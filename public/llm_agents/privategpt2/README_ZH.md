# Hello LLM - å¢å¼ºç‰ˆä¸­æ–‡å°è¯´GPTæ¨¡å‹

[English](README.md)

åŸºäºGPT-2æ¶æ„ï¼Œä»é›¶å¼€å§‹è®­ç»ƒä¸“é—¨é’ˆå¯¹ä¸­æ–‡æ­¦ä¾ å°è¯´çš„è¯­è¨€æ¨¡å‹ã€‚**è¿™æ˜¯é‡æ–°è®­ç»ƒè€Œéå¾®è°ƒï¼Œæ‹¥æœ‰å®Œæ•´çš„ä¸­æ–‡è¯æ±‡è¡¨å’Œæ­¦ä¾ æ–‡æœ¬é£æ ¼**ã€‚

## ğŸš€ æ ¸å¿ƒç‰¹æ€§

- **ä»é›¶è®­ç»ƒ**: åŸºäºGPT-2æ¶æ„ï¼Œéšæœºåˆå§‹åŒ–æƒé‡ï¼Œä¸“é—¨é’ˆå¯¹ä¸­æ–‡æ­¦ä¾ å°è¯´è®­ç»ƒ
- **GPUæ™ºèƒ½åŠ é€Ÿ**: è‡ªåŠ¨æ£€æµ‹CUDA/MPS/CPUï¼Œæ™ºèƒ½è°ƒæ•´æ‰¹æ¬¡å¤§å°å’Œè®­ç»ƒç­–ç•¥
- **ç³»ç»Ÿç¼“å­˜ä¼˜åŒ–**: æ”¯æŒHugging Faceç³»ç»Ÿç¼“å­˜ï¼Œé¿å…é‡å¤ä¸‹è½½å’Œèµ„æºæµªè´¹
- **å¢å¼ºæ•°æ®é¢„å¤„ç†**: æ™ºèƒ½æ–‡æœ¬æ¸…ç†ã€å¥å­åˆ†å‰²ã€è®­ç»ƒå—åˆ›å»ºï¼Œæå‡æ•°æ®è´¨é‡
- **ä¸­æ–‡ä¸“é¡¹ä¼˜åŒ–**: 50Kä¸­æ–‡è¯æ±‡è¡¨ï¼ŒBPEåˆ†è¯ç®—æ³•ï¼Œä¸“é—¨å¤„ç†ä¸­æ–‡æ­¦ä¾ æ–‡æœ¬
- **å†…å­˜è‡ªé€‚åº”**: æ ¹æ®ç¡¬ä»¶é…ç½®è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼Œé¿å…æ˜¾å­˜æº¢å‡º

## ğŸ“Š æŠ€æœ¯æ¶æ„å¯¹æ¯”

| ç‰¹æ€§ç»´åº¦ | é‡æ–°è®­ç»ƒ(æœ¬é¡¹ç›®) | å¾®è°ƒæ–¹æ¡ˆ | ä¼˜åŠ¿è¯´æ˜ |
|---|---|---|---|
| **å‚æ•°é‡** | 117M (GPT-2æ ‡å‡†) | 117M | ç›¸åŒè§„æ¨¡ï¼Œä½†æƒé‡é‡æ–°å­¦ä¹  |
| **è¯æ±‡è¡¨** | 50K+ä¸­æ–‡è¯æ±‡ | 50Kè‹±æ–‡è¯æ±‡ | ä¸­æ–‡è¡¨è¾¾èƒ½åŠ›æ›´å¼º |
| **è®­ç»ƒæ•°æ®** | 50+æœ¬æ­¦ä¾ å°è¯´ | é€šç”¨è‹±æ–‡è¯­æ–™ | æ­¦ä¾ æ–‡æœ¬é£æ ¼æ›´çº¯æ­£ |
| **æ–‡æœ¬é£æ ¼** | å¤å…¸ä¸­æ–‡/æ­¦ä¾ é£ | ç°ä»£è‹±æ–‡ | ä¸­æ–‡å°è¯´ç”Ÿæˆè´¨é‡æ›´é«˜ |
| **è®­ç»ƒæ—¶é—´** | 8-12å°æ—¶ | 1-2å°æ—¶ | æ›´é•¿çš„è®­ç»ƒè·å¾—æ›´å¥½æ•ˆæœ |
| **ç¡¬ä»¶éœ€æ±‚** | GPUæ¨è(8GB+) | GPUå¯é€‰ | éœ€è¦æ›´å¤šè®¡ç®—èµ„æº |
| **ç”Ÿæˆè´¨é‡** | ä¸­æ–‡æ­¦ä¾ ä¸“ç”¨ | é€šç”¨è‹±æ–‡ | åœ¨æ­¦ä¾ åœºæ™¯ä¸‹è¡¨ç°ä¼˜å¼‚ |

## ğŸ”„ å®Œæ•´æŠ€æœ¯æ¶æ„

### 1. æ•´ä½“è®­ç»ƒæµç¨‹

```mermaid
graph TD
    A[å¼€å§‹è®­ç»ƒ] --> B[æ•°æ®å‡†å¤‡é˜¶æ®µ]
    B --> C[å¢å¼ºæ–‡æœ¬é¢„å¤„ç†]
    C --> D[ä¸­æ–‡åˆ†è¯å™¨è®­ç»ƒ]
    D --> E[GPT-2æ¨¡å‹æ¶æ„åˆ›å»º]
    E --> F[GPUè®¾å¤‡æ£€æµ‹ä¸é…ç½®]
    F --> G[è®­ç»ƒå‚æ•°è‡ªé€‚åº”]
    G --> H[å¼€å§‹æ¨¡å‹è®­ç»ƒ]
    H --> I[æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜]
    I --> J[æœ€ç»ˆæ¨¡å‹è¯„ä¼°]
    J --> K[æ–‡æœ¬ç”Ÿæˆæµ‹è¯•]
    
    B -.-> B1[50+æœ¬æ­¦ä¾ å°è¯´]
    B -.-> B2[UTF-8ç¼–ç ç»Ÿä¸€]
    C -.-> C1[æ™ºèƒ½æ–‡æœ¬æ¸…ç†]
    C -.-> C2[å¥å­è¾¹ç•Œåˆ†å‰²]
    C -.-> C3[256å­—ç¬¦è®­ç»ƒå—]
    D -.-> D1[BPEç®—æ³•åˆ†è¯]
    D -.-> D2[50Kä¸­æ–‡è¯æ±‡è¡¨]
    F -.-> F1[CUDAè‡ªåŠ¨æ£€æµ‹]
    F -.-> F2[Apple MPSæ”¯æŒ]
    F -.-> F3[CPUå›é€€æ–¹æ¡ˆ]
    G -.-> G1[æ‰¹æ¬¡å¤§å°è‡ªé€‚åº”]
    G -.-> G2[å­¦ä¹ ç‡ä¼˜åŒ–]
    G -.-> G3[å†…å­˜ç®¡ç†ç­–ç•¥]
```

### 2. æ•°æ®é¢„å¤„ç†å¢å¼ºæµç¨‹

```mermaid
graph LR
    A[åŸå§‹æ­¦ä¾ æ–‡æœ¬] --> B[EnhancedTextPreprocessor]
    B --> C[æ­£åˆ™è¡¨è¾¾å¼æ¸…ç†]
    C --> D[ä¿ç•™ä¸­æ–‡å­—ç¬¦+æ ‡ç‚¹]
    D --> E[å¥å­è¾¹ç•Œæ£€æµ‹]
    E --> F[æŒ‰ã€‚ï¼ï¼Ÿåˆ†å‰²]
    F --> G[è¿‡æ»¤çŸ­å¥<10å­—ç¬¦]
    G --> H[åˆ›å»ºè®­ç»ƒå—256å­—ç¬¦]
    H --> I[è®­ç»ƒé›†90%åˆ†å‰²]
    H --> J[éªŒè¯é›†10%åˆ†å‰²]
    
    style B fill:#f9f,stroke:#333
    style H fill:#9f9,stroke:#333
```

### 3. GPUé…ç½®ä¸ä¼˜åŒ–ç­–ç•¥

```mermaid
graph TD
    A[è®¾å¤‡æ£€æµ‹] --> B{CUDAå¯ç”¨?}
    B -->|æ˜¯| C[CUDA GPU]
    B -->|å¦| D{Apple MPS?}
    D -->|æ˜¯| E[Apple Silicon MPS]
    D -->|å¦| F[CPUå›é€€]
    
    C --> G[æ˜¾å­˜å®¹é‡æ£€æµ‹]
    G --> H{æ˜¾å­˜>=8GB?}
    H -->|æ˜¯| I[æ‰¹æ¬¡å¤§å°=8]
    H -->|å¦| J{æ˜¾å­˜>=4GB?}
    J -->|æ˜¯| K[æ‰¹æ¬¡å¤§å°=4]
    J -->|å¦| L[æ‰¹æ¬¡å¤§å°=2]
    
    E --> M[æ‰¹æ¬¡å¤§å°=4]
    F --> N[æ‰¹æ¬¡å¤§å°=2]
    
    C --> O[fp16æ··åˆç²¾åº¦]
    E --> P[æ ‡å‡†ç²¾åº¦è®­ç»ƒ]
    F --> Q[å°æ‰¹æ¬¡ä¼˜åŒ–]
```

## ğŸƒâ€â™‚ï¸ å¿«é€Ÿå¼€å§‹æŒ‡å—

### ç¯å¢ƒå‡†å¤‡

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd p-llm-createprivatellm-1

# 2. åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. å‡†å¤‡è®­ç»ƒæ•°æ®ï¼ˆç¡®ä¿textç›®å½•æœ‰æ­¦ä¾ å°è¯´txtæ–‡ä»¶ï¼‰
ls text/  # åº”è¯¥èƒ½çœ‹åˆ°å¤šä¸ª.txtæ–‡ä»¶
```

### Dockerè¿è¡Œæ–¹æ¡ˆ

```bash
# æ„å»ºDockeré•œåƒ
docker build -t chinese-novel-llm:latest .

# GPUè¿è¡Œï¼ˆéœ€è¦NVIDIA Dockerè¿è¡Œæ—¶ï¼‰
docker run -it --gpus all chinese-novel-llm:latest \
    python enhance_training.py

# CPUè¿è¡Œ
docker run -it chinese-novel-llm:latest \
    python enhance_training.py --no-gpu

# å¸¦æ•°æ®å·æŒ‚è½½è¿è¡Œ
docker run -it -v $(pwd)/text:/app/text chinese-novel-llm:latest \
    python enhance_training.py
```

## ğŸ”§ æ ¸å¿ƒå®ç°è¯¦è§£

### 1. å¢å¼ºç‰ˆæ•°æ®é¢„å¤„ç†

```python
class EnhancedTextPreprocessor:
    """å¢å¼ºæ–‡æœ¬é¢„å¤„ç†å™¨ - ä¸“ä¸ºä¸­æ–‡æ­¦ä¾ æ–‡æœ¬ä¼˜åŒ–"""
    
    def __init__(self):
        # ç« èŠ‚æ ‡é¢˜æ¨¡å¼è¯†åˆ«
        self.chapter_pattern = re.compile(r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡]+[ç« èŠ‚å›é›†]', re.UNICODE)
        # å¯¹è¯å†…å®¹è¯†åˆ«
        self.dialogue_pattern = re.compile(r'[""""].*?[""""]', re.UNICODE)
        # ç©ºç™½å­—ç¬¦æ¸…ç†
        self.whitespace_pattern = re.compile(r'\s+')
    
    def clean_text(self, text):
        """æ™ºèƒ½æ–‡æœ¬æ¸…ç† - ä¿ç•™ä¸­æ–‡è¯­ä¹‰"""
        # åˆå¹¶å¤šä½™ç©ºç™½
        text = self.whitespace_pattern.sub(' ', text)
        # ä¿ç•™ä¸­æ–‡å­—ç¬¦ã€æ ‡ç‚¹å’Œå¿…è¦ç¬¦å·
        text = re.sub(r'[^\u4e00-\u9fa5\u3000-\u303f\uff00-\uffef\w\sã€‚ï¼Œï¼ï¼Ÿï¼šï¼›""""]', '', text)
        return text.strip()
    
    def split_into_sentences(self, text):
        """ä¸­æ–‡å¥å­æ™ºèƒ½åˆ†å‰²"""
        # æŒ‰ä¸­æ–‡æ ‡ç‚¹åˆ†å‰²å¥å­
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        # è¿‡æ»¤è¿‡çŸ­å¥å­ï¼ˆå°‘äº10å­—ç¬¦ï¼‰
        return [s.strip() for s in sentences if s.strip() and len(s.strip()) > 10]
    
    def create_training_chunks(self, sentences, chunk_size=256):
        """åˆ›å»º256å­—ç¬¦è®­ç»ƒå—"""
        chunks, current_chunk = [], ""
        for sentence in sentences:
            if len(current_chunk) + len(sentence) <= chunk_size:
                current_chunk += sentence + "ã€‚"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + "ã€‚"
        if current_chunk:
            chunks.append(current_chunk.strip())
        return chunks
```

### 2. GPT-2æ¨¡å‹æ¶æ„é…ç½®è¯¦è§£

```python
# GPT-2æ¨¡å‹é…ç½® - ä¸­æ–‡æ­¦ä¾ æ–‡æœ¬ä¸“ç”¨
config = GPT2Config(
    # è¯æ±‡è¡¨å¤§å° - 50Kè¦†ç›–ä¸­æ–‡å¸¸ç”¨å­—ç¬¦
    vocab_size=50000,
    
    # åµŒå…¥ç»´åº¦ - 768å¹³è¡¡æ¨¡å‹å®¹é‡ä¸è®¡ç®—æ•ˆç‡
    n_embd=768,
    
    # æ³¨æ„åŠ›å¤´æ•° - 12å¤´æä¾›å¤šæ ·åŒ–æ³¨æ„åŠ›æ¨¡å¼
    n_head=12,
    
    # Transformerå±‚æ•° - 12å±‚è¶³å¤Ÿå­¦ä¹ å¤æ‚è¯­è¨€æ¨¡å¼
    n_layer=12,
    
    # æœ€å¤§åºåˆ—é•¿åº¦ - 512é€‚åˆä¸­æ–‡å¥å­é•¿åº¦
    n_positions=512,
    
    # å‰é¦ˆç½‘ç»œç»´åº¦ - 3072=768Ã—4æ ‡å‡†æ¯”ä¾‹
    n_inner=3072,
    
    # Dropouté…ç½® - 0.1é˜²æ­¢è¿‡æ‹Ÿåˆ
    resid_pdrop=0.1,
    embd_pdrop=0.1,
    attn_pdrop=0.1,
    
    # ç‰¹æ®Šæ ‡è®°IDé…ç½®
    pad_token_id=tokenizer_chinese.token_to_id("<pad>"),
    bos_token_id=tokenizer_chinese.token_to_id("<s>"),
    eos_token_id=tokenizer_chinese.token_to_id("</s>"),
)
```

### 3. GPUå†…å­˜è‡ªé€‚åº”é…ç½®

```python
def configure_training_device():
    """GPUè®¾å¤‡æ™ºèƒ½æ£€æµ‹ä¸é…ç½®"""
    
    # CUDA GPUæ£€æµ‹
    if torch.cuda.is_available():
        device = torch.device("cuda")
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        
        # æ˜¾å­˜åˆ†çº§é…ç½®
        if gpu_memory >= 8:  # 8GB+æ˜¾å­˜
            batch_size, fp16, bf16 = 8, True, False
        elif gpu_memory >= 4:  # 4-8GBæ˜¾å­˜
            batch_size, fp16, bf16 = 4, True, False
        else:  # <4GBæ˜¾å­˜
            batch_size, fp16, bf16 = 2, False, False
            
        logger.info(f"CUDA GPU: {gpu_memory:.1f}GB, batch_size={batch_size}")
        
    # Apple MPSæ£€æµ‹
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        device = torch.device("mps")
        batch_size, fp16, bf16 = 4, False, False
        logger.info("Apple MPS detected")
        
    # CPUå›é€€
    else:
        device = torch.device("cpu")
        batch_size, fp16, bf16 = 2, False, False
        logger.info("Using CPU")
    
    return device, batch_size, fp16, bf16
```

### 4. è®­ç»ƒå‚æ•°ä¼˜åŒ–é…ç½®

```python
training_args = TrainingArguments(
    # è¾“å‡ºç›®å½•é…ç½®
    output_dir="./enhanced_output",
    overwrite_output_dir=True,
    
    # è®­ç»ƒç­–ç•¥
    num_train_epochs=30,  # 30è½®é€‚åˆä¸­æ–‡å°è¯´
    per_device_train_batch_size=batch_size,  # è‡ªé€‚åº”æ‰¹æ¬¡
    per_device_eval_batch_size=batch_size,
    gradient_accumulation_steps=8,  # æœ‰æ•ˆæ‰¹æ¬¡64
    
    # ä¼˜åŒ–å™¨é…ç½®
    learning_rate=5e-5,  # GPT-2æ¨èå­¦ä¹ ç‡
    warmup_steps=1000,   # é¢„çƒ­é¿å…åˆæœŸä¸ç¨³å®š
    weight_decay=0.01,   # L2æ­£åˆ™åŒ–
    
    # ç›‘æ§ä¸ä¿å­˜
    logging_dir="./enhanced_logs",
    logging_steps=50,
    save_steps=500,
    eval_steps=250,
    save_total_limit=3,
    load_best_model_at_end=True,
    
    # ç²¾åº¦ä¼˜åŒ–
    fp16=fp16,  # æ··åˆç²¾åº¦è®­ç»ƒ
    bf16=bf16,
    
    # æ•°æ®åŠ è½½ä¼˜åŒ–
    dataloader_num_workers=4 if device.type == "cuda" else 2,
    report_to=[],  # ç¦ç”¨wandb
)
```

## ğŸ¯ è®­ç»ƒå‘½ä»¤è¯¦è§£

### åŸºç¡€è®­ç»ƒå‘½ä»¤

```bash
# æ ‡å‡†è®­ç»ƒï¼ˆè‡ªåŠ¨GPUæ£€æµ‹ï¼‰
python enhance_training.py

# CPUè®­ç»ƒæ¨¡å¼
python enhance_training.py --no-gpu

# ä½¿ç”¨æœ¬åœ°é¢„è®­ç»ƒæƒé‡
python enhance_training.py --local-model --local-path ./models/gpt2-local

# ç¦ç”¨ç³»ç»Ÿç¼“å­˜ï¼ˆå¼ºåˆ¶é‡æ–°ä¸‹è½½ï¼‰
python enhance_training.py --no-cache

# è‡ªå®šä¹‰è¾“å‡ºç›®å½•
python enhance_training.py --output-dir ./my_model_output
```

### é«˜çº§è®­ç»ƒå‚æ•°

| å‘½ä»¤è¡Œå‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | ä½¿ç”¨åœºæ™¯ |
|---|---|---|---|
| `--no-gpu` | False | ç¦ç”¨GPUä½¿ç”¨CPUè®­ç»ƒ | æ˜¾å­˜ä¸è¶³æ—¶ |
| `--local-model` | False | ä½¿ç”¨æœ¬åœ°é¢„è®­ç»ƒæ¨¡å‹ | ç¦»çº¿ç¯å¢ƒ |
| `--local-path` | "./models/gpt2-local" | æœ¬åœ°æ¨¡å‹è·¯å¾„ | è‡ªå®šä¹‰æ¨¡å‹ |
| `--no-cache` | False | ç¦ç”¨ç³»ç»Ÿç¼“å­˜ | å¼ºåˆ¶é‡æ–°ä¸‹è½½ |
| `--output-dir` | "./enhanced_output" | æ¨¡å‹è¾“å‡ºç›®å½• | è‡ªå®šä¹‰ä¿å­˜ä½ç½® |
| `--epochs` | 30 | è®­ç»ƒè½®æ•° | å¿«é€Ÿæµ‹è¯•æ—¶å‡å°‘ |
| `--batch-size` | auto | æ‰¹æ¬¡å¤§å° | æ‰‹åŠ¨æ§åˆ¶æ˜¾å­˜ |

## ğŸ“ˆ è®­ç»ƒç›‘æ§ä¸è¯„ä¼°

### å®æ—¶æ—¥å¿—è¾“å‡º

```
==================================================
GPUè®¾å¤‡æ£€æµ‹
==================================================
âŒ CUDAä¸å¯ç”¨
âœ… Apple MPSå¯ç”¨
ğŸ–¥ï¸  é»˜è®¤è®¾å¤‡: mps
==================================================

å‘ç° 52 ä¸ªæ­¦ä¾ æ–‡æœ¬æ–‡ä»¶
å¤„ç†æ–‡ä»¶: text/å¤©é¾™å…«éƒ¨.txt â†’ æå– 1247 ä¸ªå¥å­
å¤„ç†æ–‡ä»¶: text/å°„é›•è‹±é›„ä¼ .txt â†’ æå– 985 ä¸ªå¥å­
...
åˆ›å»ºè®­ç»ƒæ•°æ®: è®­ç»ƒé›† 15,847 æ¡, éªŒè¯é›† 1,761 æ¡
æ¨¡å‹å‚æ•°é‡: 117,637,632
å¼€å§‹è®­ç»ƒ...
Epoch 1/30 - æŸå¤±: 3.8476 - å›°æƒ‘åº¦: 46.8
Epoch 2/30 - æŸå¤±: 3.1247 - å›°æƒ‘åº¦: 22.7
...
è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜åˆ°: ./enhanced_output
```

### æ€§èƒ½æŒ‡æ ‡ç›‘æ§

| æŒ‡æ ‡ | æœŸæœ›å€¼ | è¯´æ˜ |
|---|---|---|
| **è®­ç»ƒæŸå¤±** | < 3.0 | æŸå¤±è¶Šä½æ¨¡å‹è¶Šå¥½ |
| **éªŒè¯å›°æƒ‘åº¦** | < 20 | å›°æƒ‘åº¦è¶Šä½è¶Šå¥½ |
| **è®­ç»ƒé€Ÿåº¦** | > 100 steps/min | å–å†³äºç¡¬ä»¶ |
| **GPUæ˜¾å­˜** | < 90% | é¿å…æ˜¾å­˜æº¢å‡º |
| **CPUå†…å­˜** | < 8GB | åˆç†å†…å­˜ä½¿ç”¨ |

## ğŸš€ æ–‡æœ¬ç”Ÿæˆæµ‹è¯•

### äº¤äº’å¼ç”Ÿæˆ

```bash
# å¯åŠ¨äº¤äº’å¼ç”Ÿæˆ
python generate_text.py --interactive

# ç¤ºä¾‹è¾“å‡º
è¾“å…¥: éƒ­é–æ­£åœ¨ç»ƒæ­¦
è¾“å‡º: éƒ­é–æ­£åœ¨ç»ƒæ­¦åœºä¸Šè‹¦ç»ƒé™é¾™åå…«æŒï¼Œæ¯ä¸€æŒéƒ½è•´å«ç€æ·±åšçš„å†…åŠ›ã€‚æŒé£å‘¼å•¸ï¼Œå°˜åœŸé£æ‰¬ï¼Œå‘¨å›´çš„å¼Ÿå­ä»¬éƒ½çœ‹å¾—ç›®çªå£å‘†ã€‚æ´ªä¸ƒå…¬åœ¨ä¸€æ—ç‚¹å¤´å¾®ç¬‘ï¼Œå¿ƒä¸­æš—æƒ³ï¼š"è¿™å­©å­çš„æ‚Ÿæ€§æœç„¶ä¸å‡¡ã€‚"
```

### æ‰¹é‡ç”Ÿæˆæµ‹è¯•

```bash
# æ‰¹é‡ç”Ÿæˆæµ‹è¯•
python generate_text.py --batch \
    "å•å¸ƒæ‰‹æŒæ–¹å¤©ç”»æˆŸ" \
    "å°é¾™å¥³åœ¨å¤å¢“ä¸­" \
    "å¼ æ— å¿Œç»ƒæˆä¹é˜³ç¥åŠŸ" \
    --max_length 100

# é¢„æœŸè¾“å‡ºé£æ ¼
# å¤å…¸ä¸­æ–‡é£æ ¼ï¼Œæ­¦ä¾ åœºæ™¯æè¿°ï¼Œäººç‰©æ€§æ ¼ç¬¦åˆåŸè‘—
```

### ç”Ÿæˆè´¨é‡å¯¹æ¯”

| æ–‡æœ¬ç±»å‹ | é‡æ–°è®­ç»ƒæ¨¡å‹ | å¾®è°ƒè‹±æ–‡æ¨¡å‹ | ä¼˜åŠ¿ |
|---|---|---|---|
| **äººç‰©æå†™** | "é»„è“‰å·§ç¬‘å«£ç„¶ï¼Œçœ¼æ³¢æµè½¬" | "Huang Rong smiled beautifully" | ä¸­æ–‡æ„å¢ƒ |
| **æ­¦åŠŸæå†™** | "é™é¾™åå…«æŒå¨åŠ›æ— ç©·" | "dragon subduing palm powerful" | ä¸“ä¸šæœ¯è¯­ |
| **åœºæ™¯æå†™** | "æ¡ƒèŠ±å²›é£æ™¯å¦‚ç”»" | "Peach Blossom Island beautiful" | å¤å…¸æ„å¢ƒ |
| **å¯¹è¯é£æ ¼** | "åœ¨ä¸‹éƒ­é–ï¼Œè¯·æ•™äº†" | "I am Guo Jing, nice to meet you" | å¤ä»£ç¤¼ä»ª |

## ğŸ“ é¡¹ç›®æ–‡ä»¶ç»“æ„

```
p-llm-createprivatellm-1/
â”œâ”€â”€ ğŸ“ æ ¸å¿ƒè„šæœ¬
â”‚   â”œâ”€â”€ enhance_training.py      # å¢å¼ºç‰ˆè®­ç»ƒä¸»è„šæœ¬
â”‚   â”œâ”€â”€ generate_text.py         # æ–‡æœ¬ç”Ÿæˆè„šæœ¬
â”‚   â”œâ”€â”€ novel_model.py          # åŸºç¡€æ¨¡å‹å®ç°
â”‚   â””â”€â”€ train_from_pretrained.py # é¢„è®­ç»ƒå¾®è°ƒè„šæœ¬
â”œâ”€â”€ ğŸ“ è®­ç»ƒæ•°æ®
â”‚   â”œâ”€â”€ text/                   # æ­¦ä¾ å°è¯´æ–‡æœ¬
â”‚   â”‚   â”œâ”€â”€ å¤©é¾™å…«éƒ¨.txt
â”‚   â”‚   â”œâ”€â”€ å°„é›•è‹±é›„ä¼ .txt
â”‚   â”‚   â””â”€â”€ ... (50+æœ¬å°è¯´)
â”‚   â”œâ”€â”€ enhanced_train.txt      # é¢„å¤„ç†è®­ç»ƒæ•°æ®
â”‚   â””â”€â”€ enhanced_valid.txt      # é¢„å¤„ç†éªŒè¯æ•°æ®
â”œâ”€â”€ ğŸ“ æ¨¡å‹è¾“å‡º
â”‚   â”œâ”€â”€ enhanced_output/        # è®­ç»ƒæ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ enhanced_logs/          # TensorBoardæ—¥å¿—
â”‚   â””â”€â”€ chinese_novel_model/    # æœ€ç»ˆè®­ç»ƒæ¨¡å‹
â”œâ”€â”€ ğŸ“ æµ‹è¯•ä¸éªŒè¯
â”‚   â”œâ”€â”€ test_gpu_training.py    # GPUæµ‹è¯•è„šæœ¬
â”‚   â”œâ”€â”€ test_improvement.py    # æ”¹è¿›æµ‹è¯•
â”‚   â””â”€â”€ test_self_gpt2_model.py # è‡ªå®šä¹‰æ¨¡å‹æµ‹è¯•
â”œâ”€â”€ ğŸ“ æŠ€æœ¯æ–‡æ¡£
â”‚   â”œâ”€â”€ README_ZH.md           # ä¸­æ–‡æŠ€æœ¯æ–¹æ¡ˆ
â”‚   â”œâ”€â”€ README.md              # è‹±æ–‡æŠ€æœ¯æ–¹æ¡ˆ
â”‚   â”œâ”€â”€ SYSTEM_CACHE_GUIDE.md  # ç³»ç»Ÿç¼“å­˜æŒ‡å—
â”‚   â””â”€â”€ technical_document.md  # æŠ€æœ¯å®ç°ç»†èŠ‚
â””â”€â”€ ğŸ“ é…ç½®ä¸ä¾èµ–
    â”œâ”€â”€ requirements.txt        # Pythonä¾èµ–
    â”œâ”€â”€ Dockerfile              # å®¹å™¨åŒ–é…ç½®
    â””â”€â”€ .gitignore             # Gitå¿½ç•¥é…ç½®
```

## ğŸ¯ æŠ€æœ¯è¦ç‚¹æ€»ç»“

### é‡æ–°è®­ç»ƒ vs å¾®è°ƒçš„æ ¸å¿ƒå·®å¼‚

#### 1. æƒé‡åˆå§‹åŒ–å·®å¼‚
- **é‡æ–°è®­ç»ƒ**: å®Œå…¨éšæœºåˆå§‹åŒ–ï¼Œå­¦ä¹ ä¸­æ–‡æ­¦ä¾ ç‰¹å¾
- **å¾®è°ƒ**: åŸºäºè‹±æ–‡é¢„è®­ç»ƒæƒé‡ï¼Œä¿ç•™è‹±æ–‡è¯­è¨€æ¨¡å¼

#### 2. è¯æ±‡è¡¨æ„å»ºå·®å¼‚
- **é‡æ–°è®­ç»ƒ**: 50Kä¸­æ–‡è¯æ±‡ï¼Œè¦†ç›–æ­¦ä¾ æœ¯è¯­
- **å¾®è°ƒ**: 50Kè‹±æ–‡è¯æ±‡ï¼Œä¸­æ–‡è¡¨è¾¾èƒ½åŠ›æœ‰é™

#### 3. è®­ç»ƒæ•°æ®å·®å¼‚
- **é‡æ–°è®­ç»ƒ**: 50+æœ¬æ­¦ä¾ å°è¯´ï¼Œå¤å…¸ä¸­æ–‡è¯­æ–™
- **å¾®è°ƒ**: é€šç”¨è‹±æ–‡è¯­æ–™ï¼Œç°ä»£è‹±æ–‡é£æ ¼

#### 4. ç”Ÿæˆé£æ ¼å·®å¼‚
- **é‡æ–°è®­ç»ƒ**: å¤å…¸ä¸­æ–‡ã€æ­¦ä¾ æ„å¢ƒã€äººç‰©æ€§æ ¼
- **å¾®è°ƒ**: ç°ä»£è‹±æ–‡ã€é€šç”¨è¡¨è¾¾ã€ç¼ºä¹æ­¦ä¾ ç‰¹è‰²

### æ€§èƒ½ä¼˜åŒ–äº®ç‚¹

âœ… **GPUæ™ºèƒ½æ£€æµ‹**: CUDA/MPS/CPUè‡ªåŠ¨åˆ‡æ¢ï¼Œå……åˆ†åˆ©ç”¨ç¡¬ä»¶
âœ… **å†…å­˜è‡ªé€‚åº”**: æ ¹æ®æ˜¾å­˜å®¹é‡æ™ºèƒ½è°ƒæ•´æ‰¹æ¬¡å¤§å°
âœ… **ä¸­æ–‡ä¼˜åŒ–**: BPEåˆ†è¯+50Kè¯æ±‡è¡¨ï¼Œä¸­æ–‡è¡¨è¾¾æ›´å‡†ç¡®
âœ… **æ•°æ®å¢å¼º**: æ™ºèƒ½é¢„å¤„ç†æå‡è®­ç»ƒæ•°æ®è´¨é‡
âœ… **è®­ç»ƒç›‘æ§**: è¯¦ç»†æ—¥å¿—+TensorBoardå¯è§†åŒ–
âœ… **ç³»ç»Ÿç¼“å­˜**: é¿å…é‡å¤ä¸‹è½½ï¼ŒèŠ‚çœç½‘ç»œèµ„æº

### ç¡¬ä»¶éœ€æ±‚å»ºè®®

| ç¡¬ä»¶é…ç½® | æ¨èé…ç½® | æœ€ä½é…ç½® | è¯´æ˜ |
|---|---|---|---|
| **GPUæ˜¾å­˜** | 8GB+ | 4GB | å†³å®šæ‰¹æ¬¡å¤§å°å’Œè®­ç»ƒé€Ÿåº¦ |
| **ç³»ç»Ÿå†…å­˜** | 16GB+ | 8GB | å½±å“æ•°æ®åŠ è½½å’Œç¼“å­˜ |
| **å­˜å‚¨ç©ºé—´** | 50GB+ | 20GB | æ¨¡å‹å’Œæ•°æ®å­˜å‚¨ |
| **CPUæ ¸å¿ƒ** | 8æ ¸+ | 4æ ¸ | å½±å“æ•°æ®é¢„å¤„ç†é€Ÿåº¦ |

## ğŸ” æ•…éšœæ’é™¤æŒ‡å—

### å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ

#### 1. CUDAå†…å­˜ä¸è¶³
```bash
# è§£å†³æ–¹æ¡ˆ1: å‡å°‘æ‰¹æ¬¡å¤§å°
python enhance_training.py --batch-size 2

# è§£å†³æ–¹æ¡ˆ2: ä½¿ç”¨CPUè®­ç»ƒ
python enhance_training.py --no-gpu
```

#### 2. æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨ç³»ç»Ÿç¼“å­˜
python enhance_training.py --no-cache

# æˆ–è€…æ£€æŸ¥æœ¬åœ°æ¨¡å‹è·¯å¾„
ls -la models/gpt2-local/
```

#### 3. ä¸­æ–‡ä¹±ç é—®é¢˜
```bash
# æ£€æŸ¥æ–‡ä»¶ç¼–ç 
file -i text/*.txt
# åº”è¯¥æ˜¾ç¤º: text/plain; charset=utf-8

# è½¬æ¢ç¼–ç ï¼ˆå¦‚æœ‰éœ€è¦ï¼‰
python convert_to_utf8.py
```

#### 4. è®­ç»ƒé€Ÿåº¦è¿‡æ…¢
```bash
# æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨
python test_gpu_training.py

# ç¡®è®¤è®¾å¤‡æ£€æµ‹
python -c "import torch; print(torch.cuda.is_available())"
```

### æ€§èƒ½è°ƒä¼˜å»ºè®®

1. **GPUä¼˜åŒ–**: ä½¿ç”¨NVIDIA RTX 3060/3070å¯è·å¾—æœ€ä½³æ€§ä»·æ¯”
2. **å†…å­˜ä¼˜åŒ–**: å…³é—­å…¶ä»–åº”ç”¨ï¼Œé¢„ç•™è¶³å¤Ÿç³»ç»Ÿå†…å­˜
3. **å­˜å‚¨ä¼˜åŒ–**: ä½¿ç”¨SSDå­˜å‚¨è®­ç»ƒæ•°æ®ï¼Œæå‡IOæ€§èƒ½
4. **ç›‘æ§å·¥å…·**: ä½¿ç”¨htop/nvidia-smiå®æ—¶ç›‘æ§ç³»ç»Ÿèµ„æº

---

**æŠ€æœ¯æ”¯æŒ**: å¦‚æœ‰é—®é¢˜è¯·æŸ¥çœ‹æŠ€æœ¯æ–‡æ¡£æˆ–æäº¤issue
**æ›´æ–°æ—¥å¿—**: 2024å¹´12æœˆ - å¢å¼ºç‰ˆè®­ç»ƒæµç¨‹ä¼˜åŒ–
