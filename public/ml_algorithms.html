<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>机器学习十大算法详解</title>
    <!-- 引入Prism.js用于代码高亮 -->
    <link href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    <!-- 引入KaTeX用于数学公式渲染 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css">
    <!-- 引入html2canvas用于页面截图 -->
    <script src="https://html2canvas.hertzen.com/dist/html2canvas.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Arial', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        header {
            text-align: center;
            padding: 50px 0;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            margin-bottom: 40px;
            position: relative;
        }

        .screenshot-btn {
            position: fixed;
            top: 20px;
            right: 20px;
            padding: 12px 24px;
            background: #4CAF50;
            color: white;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            z-index: 1000;
            font-size: 16px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
            transition: all 0.3s ease;
        }

        .screenshot-btn:hover {
            background: #45a049;
            transform: translateY(-2px);
        }

        .algorithm-section {
            background: white;
            border-radius: 10px;
            padding: 30px;
            margin-bottom: 30px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }

        h1 {
            font-size: 2.5em;
            margin-bottom: 20px;
        }

        h2 {
            font-size: 1.8em;
            color: #4a5568;
            margin-bottom: 20px;
            border-bottom: 2px solid #e2e8f0;
            padding-bottom: 10px;
        }

        h3 {
            font-size: 1.4em;
            color: #2d3748;
            margin: 20px 0 10px;
        }

        p {
            margin-bottom: 15px;
            font-size: 1.1em;
        }

        code {
            font-family: 'Courier New', Courier, monospace;
        }

        pre {
            font-family: 'Courier New', Courier, monospace;
            white-space: pre-wrap;
        }

        ul {
            margin-left: 20px;
            margin-bottom: 15px;
        }

        .code-block {
            background: #282c34;
            padding: 20px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 20px 0;
        }

        .math-block {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
            text-align: center;
        }

        .pros-cons {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }

        .pros, .cons {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
        }

        .pros h4, .cons h4 {
            color: #2d3748;
            margin-bottom: 10px;
        }

        .pros {
            border-left: 4px solid #48bb78;
        }

        .cons {
            border-left: 4px solid #f56565;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        th, td {
            padding: 12px;
            border: 1px solid #e2e8f0;
            text-align: left;
        }

        th {
            background: #f7fafc;
        }

        .loading {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(255, 255, 255, 0.9);
            display: none;
            justify-content: center;
            align-items: center;
            z-index: 1000;
        }

        .loading-text {
            font-size: 1.2em;
            color: #4a5568;
        }

        blockquote {
            background: #f9f9f9;
            border-left: 5px solid #6b7280;
            margin: 20px 0;
            padding: 15px;
            font-style: italic;
        }

        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }
            
            .pros-cons {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div id="loading" class="loading">
        <div class="loading-text">正在生成截图...</div>
    </div>
    
    <button class="screenshot-btn" onclick="captureScreenshots()">保存为图片</button>

    <header>
        <div class="container">
            <h1>机器学习十大算法详解</h1>
            <p>从原理到实践的完整指南</p>
        </div>
    </header>

    <div class="container" id="content">
        <!-- 算法1：线性回归 -->
        <section class="algorithm-section" id="linear-regression">
            <h2>1. 线性回归（Linear Regression）</h2>
            <h3>原理</h3>
            <p>通过最小化预测值与真实值的均方误差（MSE），找到最佳线性关系：</p>
            <div class="math-block">
                <span class="katex-render">(min_{w} frac{1}{n} sum_{i=1}^{n} (y_i - w^T x_i)^2)</span>
            </div>

            <div class="pros-cons">
                <div class="pros">
                    <h4>优点</h4>
                    <ul>
                        <li>计算效率高</li>
                        <li>可解释性强</li>
                    </ul>
                </div>
                <div class="cons">
                    <h4>缺点</h4>
                    <ul>
                        <li>对非线性关系建模能力差</li>
                    </ul>
                </div>
            </div>

            <h3>案例：房价预测（波士顿房价数据集）</h3>
            <div class="code-block">
                <pre><code class="language-python">
from sklearn.datasets import load_boston
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# 加载数据
data = load_boston()
X, y = data.data, data.target

# 训练模型
model = LinearRegression()
model.fit(X, y)

# 评估
preds = model.predict(X)
print(f"MSE: {mean_squared_error(y, preds):.2f}")
                </code></pre>
            </div>
        </section>

        <!-- 算法2：逻辑回归 -->
        <section class="algorithm-section" id="logistic-regression">
            <h2>2. 逻辑回归（Logistic Regression）</h2>
            <h3>原理</h3>
            <p>使用Sigmoid函数将线性输出映射到概率：</p>
            <div class="math-block">
                <span class="katex-render">(P(y=1|x) = frac{1}{1 + e^{-w^T x}})</span>
            </div>

            <div class="pros-cons">
                <div class="pros">
                    <h4>优点</h4>
                    <ul>
                        <li>输出概率解释性强</li>
                        <li>训练速度快</li>
                        <li>适合处理线性可分问题</li>
                    </ul>
                </div>
                <div class="cons">
                    <h4>缺点</h4>
                    <ul>
                        <li>需手动处理特征相关性</li>
                        <li>对非线性边界表现不佳</li>
                    </ul>
                </div>
            </div>

            <h3>案例：信用卡欺诈检测（Kaggle数据集）</h3>
            <div class="code-block">
                <pre><code class="language-python">
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score

# 假设X_train为标准化后的特征矩阵
model = LogisticRegression(class_weight='balanced')
model.fit(X_train, y_train)

prob = model.predict_proba(X_test)[:, 1]
print(f"AUC: {roc_auc_score(y_test, prob):.3f}")
                </code></pre>
            </div>
        </section>

        <!-- 算法3：决策树 -->
        <section class="algorithm-section" id="decision-tree">
            <h2>3. 决策树（Decision Tree）</h2>
            <h3>原理</h3>
            <p>递归选择信息增益最大的特征进行分裂（ID3/C4.5算法），通过树结构进行决策。</p>

            <div class="pros-cons">
                <div class="pros">
                    <h4>优点</h4>
                    <ul>
                        <li>直观易解释</li>
                        <li>无需特征缩放</li>
                        <li>可处理分类和回归问题</li>
                    </ul>
                </div>
                <div class="cons">
                    <h4>缺点</h4>
                    <ul>
                        <li>容易过拟合</li>
                        <li>对数据扰动敏感</li>
                    </ul>
                </div>
            </div>

            <h3>案例：鸢尾花分类</h3>
            <div class="code-block">
                <pre><code class="language-python">
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree

# 训练决策树
clf = DecisionTreeClassifier(max_depth=3)
clf.fit(X_train, y_train)

# 可视化
tree.plot_tree(clf, feature_names=iris.feature_names)
                </code></pre>
            </div>
        </section>

        <!-- 算法4：随机森林 -->
        <section class="algorithm-section" id="random-forest">
            <h2>4. 随机森林（Random Forest）</h2>
            <h3>原理</h3>
            <p>通过Bootstrap采样和特征随机选择构建多棵决策树，投票决定结果。这种集成方法通过多样性来减少过拟合。</p>

            <div class="pros-cons">
                <div class="pros">
                    <h4>优点</h4>
                    <ul>
                        <li>抗过拟合能力强</li>
                        <li>处理高维数据能力好</li>
                        <li>能估计特征重要性</li>
                    </ul>
                </div>
                <div class="cons">
                    <h4>缺点</h4>
                    <ul>
                        <li>计算资源消耗大</li>
                        <li>模型解释性不如单棵决策树</li>
                    </ul>
                </div>
            </div>

            <h3>案例：客户流失预测</h3>
            <div class="code-block">
                <pre><code class="language-python">
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(
    n_estimators=200,
    max_features='sqrt'
)
model.fit(X_train, y_train)

print(f"重要特征：{model.feature_importances_}")
                </code></pre>
            </div>
        </section>

        <!-- 算法5：支持向量机 -->
        <section class="algorithm-section" id="svm">
            <h2>5. 支持向量机（SVM）</h2>
            <h3>原理</h3>
            <p>寻找最大化间隔的超平面，通过核技巧处理非线性问题：</p>
            <div class="math-block">
                <span class="katex-render">(min_{w,b} frac{1}{2}||w||^2 + Csum xi_i)</span>
            </div>

            <div class="pros-cons">
                <div class="pros">
                    <h4>优点</h4>
                    <ul>
                        <li>在高维空间表现优异</li>
                        <li>对噪声有较强鲁棒性</li>
                        <li>通过核函数灵活处理非线性边界</li>
                    </ul>
                </div>
                <div class="cons">
                    <h4>缺点</h4>
                    <ul>
                        <li>大规模数据训练慢</li>
                        <li>对参数敏感，调优复杂</li>
                    </ul>
                </div>
            </div>

            <h3>案例：手写数字识别（MNIST）</h3>
            <div class="code-block">
                <pre><code class="language-python">
from sklearn.svm import SVC

model = SVC(kernel='rbf', gamma='scale')
model.fit(X_train, y_train)

print(f"准确率：{model.score(X_test, y_test):.2%}")
                </code></pre>
            </div>
        </section>

        <!-- 算法6：K近邻 -->
        <section class="algorithm-section" id="knn">
            <h2>6. K近邻（K-NN）</h2>
            <h3>原理</h3>
            <p>根据k个最近邻样本的多数投票进行分类，或平均值进行回归。KNN是一种懒惰学习，不需要显式的训练过程。</p>

            <div class="pros-cons">
                <div class="pros">
                    <h4>优点</h4>
                    <ul>
                        <li>无需训练，实现简单</li>
                        <li>适应局部模式变化</li>
                        <li>对数据分布无假设</li>
                    </ul>
                </div>
                <div class="cons">
                    <h4>缺点</h4>
                    <ul>
                        <li>计算复杂度随数据量线性增长</li>
                        <li>对特征缩放敏感</li>
                        <li>维度灾难问题</li>
                    </ul>
                </div>
            </div>

            <h3>案例：电影推荐（基于用户评分）</h3>
            <div class="code-block">
                <pre><code class="language-python">
from sklearn.neighbors import KNeighborsClassifier

model = KNeighborsClassifier(
    n_neighbors=5,
    metric='cosine' # 使用余弦相似度
)
model.fit(user_vectors, movie_ratings)
                </code></pre>
            </div>
        </section>

        <!-- 算法7：K均值 -->
        <section class="algorithm-section" id="kmeans">
            <h2>7. K均值（K-Means）</h2>
            <h3>原理</h3>
            <p>迭代优化簇内样本到质心的距离，是最常用的聚类算法之一：</p>
            <div class="math-block">
                <span class="katex-render">(min sum_{i=1}^{k} sum_{x in C_i} ||x - mu_i||^2)</span>
            </div>

            <div class="pros-cons">
                <div class="pros">
                    <h4>优点</h4>
                    <ul>
                        <li>简单高效，易于实现</li>
                        <li>适合大数据场景</li>
                        <li>收敛速度快</li>
                    </ul>
                </div>
                <div class="cons">
                    <h4>缺点</h4>
                    <ul>
                        <li>需预先指定簇数k</li>
                        <li>对初始质心敏感</li>
                        <li>对异常值敏感</li>
                    </ul>
                </div>
            </div>

            <h3>案例：客户分群（电商数据）</h3>
            <div class="code-block">
                <pre><code class="language-python">
from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=5)
kmeans.fit(customer_features)

# 分析聚类结果
plt.scatter(X[:,0], X[:,1], c=kmeans.labels_)
                </code></pre>
            </div>
        </section>

        <!-- 算法8：朴素贝叶斯 -->
        <section class="algorithm-section" id="naive-bayes">
            <h2>8. 朴素贝叶斯（Naive Bayes）</h2>
            <h3>原理</h3>
            <p>基于贝叶斯定理与特征条件独立假设的分类方法：</p>
            <div class="math-block">
                <span class="katex-render">(P(y|x) propto P(y) prod P(x_i|y))</span>
            </div>

            <div class="pros-cons">
                <div class="pros">
                    <h4>优点</h4>
                    <ul>
                        <li>小样本表现好</li>
                        <li>训练和预测速度快</li>
                        <li>适合文本分类任务</li>
                    </ul>
                </div>
                <div class="cons">
                    <h4>缺点</h4>
                    <ul>
                        <li>特征独立性假设不现实</li>
                        <li>对零概率处理需谨慎</li>
                    </ul>
                </div>
            </div>

            <h3>案例：垃圾邮件过滤</h3>
            <div class="code-block">
                <pre><code class="language-python">
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer

# 文本向量化
vectorizer = TfidfVectorizer()
X_train = vectorizer.fit_transform(emails)

# 训练模型
model = MultinomialNB()
model.fit(X_train, labels)
                </code></pre>
            </div>
        </section>

        <!-- 算法9：梯度提升树 -->
        <section class="algorithm-section" id="xgboost">
            <h2>9. 梯度提升树（XGBoost）</h2>
            <h3>原理</h3>
            <p>通过加法模型逐步拟合残差，每步训练一个弱学习器：</p>
            <div class="math-block">
                <span class="katex-render">(F_m(x) = F_{m-1}(x) + gamma_m h_m(x))</span>
            </div>

            <div class="pros-cons">
                <div class="pros">
                    <h4>优点</h4>
                    <ul>
                        <li>预测准确度高</li>
                        <li>处理缺失值能力强</li>
                        <li>可用于分类和回归</li>
                    </ul>
                </div>
                <div class="cons">
                    <h4>缺点</h4>
                    <ul>
                        <li>参数调优复杂</li>
                        <li>训练时间长</li>
                        <li>解释性不如单棵决策树</li>
                    </ul>
                </div>
            </div>

            <h3>案例：销售额预测</h3>
            <div class="code-block">
                <pre><code class="language-python">
import xgboost as xgb

dtrain = xgb.DMatrix(X_train, label=y_train)
params = {
    'max_depth': 6,
    'eta': 0.1,
    'objective': 'reg:squarederror'
}

model = xgb.train(params, dtrain, num_boost_round=100)
                </code></pre>
            </div>
        </section>

        <!-- 算法10：神经网络 -->
        <section class="algorithm-section" id="neural-network">
            <h2>10. 神经网络（Neural Network）</h2>
            <h3>原理</h3>
            <p>通过多层非线性变换学习特征表示，模拟人脑神经元工作方式：</p>
            <div class="math-block">
                <span class="katex-render">(y = sigma(W_n cdot sigma(W_{n-1} cdots sigma(W_1 x))))</span>
            </div>

            <div class="pros-cons">
                <div class="pros">
                    <h4>优点</h4>
                    <ul>
                        <li>表征能力极强</li>
                        <li>适合复杂非结构化数据</li>
                        <li>端到端学习能力</li>
                    </ul>
                </div>
                <div class="cons">
                    <h4>缺点</h4>
                    <ul>
                        <li>需要大量数据</li>
                        <li>计算资源需求高</li>
                        <li>可解释性差</li>
                    </ul>
                </div>
            </div>

            <h3>案例：图像分类（PyTorch实现）</h3>
            <div class="code-block">
                <pre><code class="language-python">
import torch
from torchvision.models import resnet18

model = resnet18(pretrained=True)
model.fc = torch.nn.Linear(512, 10) # 修改输出层

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# 训练循环
for epoch in range(10):
    for inputs, labels in dataloader:
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
                </code></pre>
            </div>
        </section>

        <!-- 算法选择指南 -->
        <section class="algorithm-section" id="selection-guide">
            <h2>算法选择指南</h2>
            <table>
                <thead>
                    <tr>
                        <th>问题类型</th>
                        <th>推荐算法</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>小样本分类</td>
                        <td>朴素贝叶斯、SVM</td>
                    </tr>
                    <tr>
                        <td>高维稀疏数据</td>
                        <td>逻辑回归、XGBoost</td>
                    </tr>
                    <tr>
                        <td>实时预测需求</td>
                        <td>决策树、K-NN</td>
                    </tr>
                    <tr>
                        <td>非结构化数据</td>
                        <td>神经网络</td>
                    </tr>
                    <tr>
                        <td>无标签数据</td>
                        <td>K-Means、自编码器</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <!-- 最佳实践建议 -->
        <section class="algorithm-section" id="best-practices">
            <h2>最佳实践建议</h2>
            <ul>
                <li><strong>数据预处理</strong>：缺失值处理/标准化比算法选择更重要</li>
                <li><strong>评估指标</strong>：分类用F1-score，回归用MAE+RMSE组合</li>
                <li><strong>模型解释</strong>：SHAP/LIME解释黑盒模型决策过程</li>
                <li><strong>部署优化</strong>：使用ONNX格式实现跨平台部署</li>
            </ul>
            
            <blockquote>
                <p>选择合适的算法只是成功的一半，真正的挑战在于理解数据，并将模型有效地应用到业务中。</p>
            </blockquote>
        </section>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
    <script>
        document.addEventListener('DOMContentLoaded', function() {
            document.querySelectorAll('.katex-render').forEach(block => {
                try {
                    const formula = block.textContent.trim();
                    katex.render(formula, block, {
                        throwOnError: false,
                        displayMode: true
                    });
                } catch (e) {
                    console.error("KaTeX error:", e);
                }
            });
        });


        // 截图功能
        async function captureScreenshots() {
            const loading = document.getElementById('loading');
            loading.style.display = 'flex';

            try {
                const content = document.getElementById('content');
                const sections = content.getElementsByClassName('algorithm-section');
                let index = 1;

                for (let section of sections) {
                    const canvas = await html2canvas(section, {
                        scale: 2,
                        logging: false,
                        useCORS: true
                    });

                    // 创建下载链接
                    const link = document.createElement('a');
                    link.download = `ml-algorithm-${index}.png`;
                    link.href = canvas.toDataURL('image/png');
                    link.click();
                    index++;

                    // 等待一小段时间再继续下一张截图
                    await new Promise(resolve => setTimeout(resolve, 500));
                }

                alert('截图已完成！');
            } catch (error) {
                console.error('截图过程出错：', error);
                alert('截图过程出现错误，请查看控制台了解详情。');
            } finally {
                loading.style.display = 'none';
            }
        }
    </script>
</body>
</html>
