# å‡çº§åçš„ä»£ç ï¼šä½¿ç”¨æœ€æ–°LangChainç‰ˆæœ¬å’Œæœ¬åœ°Ollamaæ¨¡å‹
from langchain_ollama import OllamaLLM as Ollama
from langchain_core.prompts import PromptTemplate
from langchain.chains import LLMChain, SequentialChain
import warnings
warnings.filterwarnings('ignore')

# é…ç½®Ollamaæ¨¡å‹
ollama_model = Ollama(
    model="gpt-3.5-turbo:latest",
    base_url="http://localhost:11434",  # Ollamaé»˜è®¤åœ°å€
    temperature=0.9,
    num_predict=1024  # ç›¸å½“äºmax_tokens
)

# åˆ›å»ºç¼–å‰§é“¾
script_prompt_tpl = PromptTemplate.from_template(
    '''ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„ç¼–å‰§ã€‚è¯·ä½¿ç”¨ä½ ä¸°å¯Œçš„æƒ³è±¡åŠ›æ ¹æ®ç»™å®šçš„æ ‡é¢˜ç¼–å†™ä¸€ä¸ªæ•…äº‹æ¦‚è¦ã€‚
    
    æ ‡é¢˜: {title}
    
    è¦æ±‚ï¼š
    1. æ•…äº‹è¦æœ‰è¶£ä¸”å¯Œæœ‰åˆ›æ„
    2. åŒ…å«å†²çªå’Œè½¬æŠ˜
    3. é€‚åˆæ”¹ç¼–æˆçŸ­è§†é¢‘
    4. å­—æ•°æ§åˆ¶åœ¨300å­—ä»¥å†…
    
    æ•…äº‹æ¦‚è¦:'''
)

script_chain = LLMChain(
    llm=ollama_model,
    prompt=script_prompt_tpl,
    output_key="story"
)

# åˆ›å»ºå¹¿å‘Šé“¾
adv_prompt_tpl = PromptTemplate.from_template(
    '''ä½ æ˜¯ä¸€ä¸ªä¼˜ç§€çš„å¹¿å‘Šå†™æ‰‹ã€‚è¯·æ ¹æ®æ•…äº‹æ¦‚è¦ï¼Œå†™ä¸€æ®µç®€çŸ­ä½†æœ‰å¸å¼•åŠ›çš„å¹¿å‘Šè¯ã€‚
    
    æ•…äº‹æ¦‚è¦: {story}
    
    è¦æ±‚ï¼š
    1. å¹¿å‘Šè¯ä¸è¶…è¿‡50å­—
    2. è¦æœ‰æ‚¬å¿µå’Œå¸å¼•åŠ›
    3. é€‚åˆç¤¾äº¤åª’ä½“ä¼ æ’­
    
    å¹¿å‘Šè¯:'''
)

# ä¸ºå¹¿å‘Šé“¾ä½¿ç”¨ç¨å¾®ä½ä¸€ç‚¹çš„temperature
adv_ollama_model = Ollama(
    model="gpt-3.5-turbo:latest",
    base_url="http://localhost:11434",
    temperature=0.6,  # é™ä½éšæœºæ€§ï¼Œä½¿å¹¿å‘Šè¯æ›´ç²¾ç‚¼
    num_predict=128   # é™åˆ¶è¾“å‡ºé•¿åº¦
)

adv_chain = LLMChain(
    llm=adv_ollama_model,
    prompt=adv_prompt_tpl,
    output_key="advertisement"
)

# ä½¿ç”¨SequentialChainæ›¿ä»£å·²å¼ƒç”¨çš„SimpleSequentialChain
chain = SequentialChain(
    chains=[script_chain, adv_chain],
    input_variables=["title"],
    output_variables=["story", "advertisement"],
    verbose=True
)

# è¿è¡Œç¤ºä¾‹
def run_story_generator(title="åœ¨æ­å·çš„â€˜è¥¿æ¹–é‡è§æ•¦ç…Œâ€™çš„è‰ºæœ¯ç©ºé—´â€™"):
    """è¿è¡Œæ•…äº‹ç”Ÿæˆå™¨"""
    try:
        result = chain.invoke({"title": title})
        
        print("=" * 50)
        print("ğŸ¬ æ•…äº‹æ ‡é¢˜:", title)
        print("=" * 50)
        print("ğŸ“– æ•…äº‹æ¦‚è¦:")
        print(result["story"])
        print("=" * 50)
        print("ğŸ“¢ å¹¿å‘Šè¯:")
        print(result["advertisement"])
        print("=" * 50)
        
        return result
        
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        print("è¯·ç¡®ä¿OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ: ollama serve")
        print("å¹¶ç¡®è®¤å·²æ‹‰å–æ¨¡å‹: ollama pull gpt-3.5-turbo:latest")
        return None

# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    # æµ‹è¯•è¿è¡Œ
    run_story_generator("åœ¨æ­å·çš„â€˜è¥¿æ¹–é‡è§æ•¦ç…Œâ€™çš„è‰ºæœ¯ç©ºé—´â€™")
    
    # ä¹Ÿå¯ä»¥è‡ªå®šä¹‰æ ‡é¢˜
    # run_story_generator("AIè§‰é†’çš„ç¨‹åºå‘˜")