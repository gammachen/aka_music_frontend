#!/usr/bin/env python3
"""
LangChainè¯„ä¼°ç³»ç»Ÿä¸»å¯åŠ¨è„šæœ¬
åŸºäºŽOllamaæœ¬åœ°æ¨¡åž‹çš„å®Œæ•´è¯„ä¼°è§£å†³æ–¹æ¡ˆ
"""

import os
import sys
import json
import subprocess
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½çŽ¯å¢ƒå˜é‡
load_dotenv()

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def check_ollama():
    """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
    try:
        import requests
        base_url = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        response = requests.get(f"{base_url}/api/tags", timeout=5)
        if response.status_code == 200:
            models_data = response.json()
            models = models_data.get("models", [])
            model_names = [m.get("name") for m in models]
            
            required_model = os.getenv("OLLAMA_MODEL", "gpt-3.5-turbo")
            full_model_name = f"{required_model}:latest"
            
            if full_model_name in model_names:
                print(f"âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸ï¼Œæ‰¾åˆ°æ¨¡åž‹: {full_model_name}")
                return True
            elif required_model in model_names:
                print(f"âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸ï¼Œæ‰¾åˆ°æ¨¡åž‹: {required_model}")
                return True
            else:
                print(f"âš ï¸  æ¨¡åž‹ {required_model} æœªæ‰¾åˆ°ï¼Œå¯ç”¨æ¨¡åž‹: {model_names}")
                print(f"è¯·è¿è¡Œ: ollama pull {required_model}")
                
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ¨¡åž‹ä½œä¸ºå¤‡é€‰
                if model_names:
                    selected_model = model_names[0]
                    print(f"ä½¿ç”¨å¤‡é€‰æ¨¡åž‹: {selected_model}")
                    # æ›´æ–°çŽ¯å¢ƒå˜é‡
                    os.environ["OLLAMA_MODEL"] = selected_model.replace(":latest", "")
                    return True
                else:
                    print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡åž‹")
                    return False
        else:
            print("âŒ OllamaæœåŠ¡å“åº”å¼‚å¸¸")
            return False
    except Exception as e:
        print(f"âŒ æ— æ³•è¿žæŽ¥OllamaæœåŠ¡: {e}")
        print("è¯·ç¡®ä¿Ollamaå·²å¯åŠ¨: ollama serve")
        return False

def install_requirements():
    """å®‰è£…ä¾èµ–åŒ…"""
    try:
        subprocess.run([sys.executable, "-m", "pip", "install", "-r", "requirements.txt"], 
                      check=True, capture_output=True)
        print("âœ… ä¾èµ–åŒ…å®‰è£…å®Œæˆ")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ ä¾èµ–åŒ…å®‰è£…å¤±è´¥: {e}")
        return False

def run_basic_tests():
    """è¿è¡ŒåŸºç¡€æµ‹è¯•"""
    try:
        from test_evaluators import test_string_evaluator
        
        print("\n" + "="*60)
        print("è¿è¡ŒåŸºç¡€è¯„ä¼°å™¨æµ‹è¯•...")
        print("="*60)
        
        test_string_evaluator()
        return True
        
    except Exception as e:
        print(f"âŒ åŸºç¡€æµ‹è¯•å¤±è´¥: {e}")
        return False

def run_custom_evaluations():
    """è¿è¡Œè‡ªå®šä¹‰è¯„ä¼°"""
    try:
        from custom_evaluators import test_custom_evaluators
        
        print("\n" + "="*60)
        print("è¿è¡Œè‡ªå®šä¹‰è¯„ä¼°å™¨æµ‹è¯•...")
        print("="*60)
        
        test_custom_evaluators()
        return True
        
    except Exception as e:
        print(f"âŒ è‡ªå®šä¹‰è¯„ä¼°å¤±è´¥: {e}")
        return False

def run_batch_evaluation():
    """è¿è¡Œæ‰¹é‡è¯„ä¼°"""
    try:
        from batch_runner import main as batch_main
        
        print("\n" + "="*60)
        print("è¿è¡Œæ‰¹é‡è¯„ä¼°...")
        print("="*60)
        
        batch_main()
        return True
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡è¯„ä¼°å¤±è´¥: {e}")
        return False

def create_demo_dataset():
    """åˆ›å»ºæ¼”ç¤ºæ•°æ®é›†"""
    demo_data = {
        "demo_qa": {
            "q1": {
                "input": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
                "reference": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä¸“æ³¨äºŽå¼€å‘èƒ½å¤Ÿä»Žæ•°æ®ä¸­å­¦ä¹ å¹¶åšå‡ºé¢„æµ‹çš„ç®—æ³•å’Œç»Ÿè®¡æ¨¡åž‹ã€‚"
            },
            "q2": {
                "input": "Pythonçš„ä¸»è¦ç‰¹ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ",
                "reference": "Pythonçš„ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼šç®€æ´æ˜“è¯»çš„è¯­æ³•ã€ä¸°å¯Œçš„æ ‡å‡†åº“ã€è·¨å¹³å°æ”¯æŒã€åŠ¨æ€ç±»åž‹ç³»ç»Ÿã€å¼ºå¤§çš„ç¬¬ä¸‰æ–¹ç”Ÿæ€ã€‚"
            },
            "q3": {
                "input": "å¦‚ä½•å­¦ä¹ ç¼–ç¨‹ï¼Ÿ",
                "reference": "å­¦ä¹ ç¼–ç¨‹çš„å»ºè®®ï¼š1)é€‰æ‹©ä¸€é—¨è¯­è¨€å¼€å§‹ï¼›2)ç†è§£åŸºç¡€æ¦‚å¿µï¼›3)åŠ¨æ‰‹å®žè·µé¡¹ç›®ï¼›4)é˜…è¯»ä¼˜ç§€ä»£ç ï¼›5)å‚ä¸Žå¼€æºç¤¾åŒºã€‚"
            }
        },
        "demo_comparison": {
            "c1": {
                "input": "è§£é‡Šä»€ä¹ˆæ˜¯API",
                "prediction_a": "APIæ˜¯åº”ç”¨ç¨‹åºç¼–ç¨‹æŽ¥å£ï¼Œå…è®¸ä¸åŒè½¯ä»¶ç³»ç»Ÿä¹‹é—´è¿›è¡Œé€šä¿¡ã€‚",
                "prediction_b": "APIå°±æ˜¯æŽ¥å£ï¼Œè®©ç¨‹åºä¹‹é—´å¯ä»¥äº’ç›¸è°ƒç”¨åŠŸèƒ½ã€‚"
            }
        }
    }
    
    with open("demo_dataset.json", "w", encoding="utf-8") as f:
        json.dump(demo_data, f, ensure_ascii=False, indent=2)
    
    print("âœ… æ¼”ç¤ºæ•°æ®é›†å·²åˆ›å»º: demo_dataset.json")

def show_menu():
    """æ˜¾ç¤ºäº¤äº’å¼èœå•"""
    print("\n" + "="*60)
    print("LangChainè¯„ä¼°ç³»ç»Ÿ - ä¸»èœå•")
    print("="*60)
    print("1. è¿è¡ŒåŸºç¡€è¯„ä¼°å™¨æµ‹è¯•")
    print("2. è¿è¡Œè‡ªå®šä¹‰è¯„ä¼°å™¨æµ‹è¯•")
    print("3. è¿è¡Œæ‰¹é‡è¯„ä¼°")
    print("4. åˆ›å»ºæ¼”ç¤ºæ•°æ®é›†")
    print("5. è¿è¡Œå…¨éƒ¨æµ‹è¯•")
    print("0. é€€å‡º")
    print("-"*60)

def main():
    """ä¸»å‡½æ•°"""
    
    print("ðŸš€ LangChainè¯„ä¼°ç³»ç»Ÿå¯åŠ¨ä¸­...")
    
    # æ£€æŸ¥çŽ¯å¢ƒ
    if not check_ollama():
        return
    
    # å®‰è£…ä¾èµ–
    if not install_requirements():
        return
    
    print("\nâœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    while True:
        show_menu()
        
        try:
            choice = input("\nè¯·é€‰æ‹©æ“ä½œ [0-5]: ").strip()
            
            if choice == "1":
                run_basic_tests()
            elif choice == "2":
                run_custom_evaluations()
            elif choice == "3":
                run_batch_evaluation()
            elif choice == "4":
                create_demo_dataset()
            elif choice == "5":
                print("è¿è¡Œå…¨éƒ¨æµ‹è¯•...")
                run_basic_tests()
                run_custom_evaluations()
                run_batch_evaluation()
            elif choice == "0":
                print("æ„Ÿè°¢ä½¿ç”¨ï¼å†è§ ðŸ‘‹")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•")
                
        except KeyboardInterrupt:
            print("\nç¨‹åºè¢«ä¸­æ–­")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    # å¦‚æžœç›´æŽ¥è¿è¡Œï¼Œæ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        if sys.argv[1] == "--check":
            check_ollama()
        elif sys.argv[1] == "--install":
            install_requirements()
        elif sys.argv[1] == "--test":
            run_basic_tests()
        elif sys.argv[1] == "--batch":
            run_batch_evaluation()
        else:
            print("ç”¨æ³•: python run_evaluation.py [--check|--install|--test|--batch]")
    else:
        main()