#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•Chainç¤ºä¾‹è„šæœ¬
"""

from langchain_ollama import OllamaLLM as Ollama

def test_ollama_connection():
    """æµ‹è¯•Ollamaè¿æ¥"""
    try:
        llm = Ollama(
            model="gpt-3.5-turbo:latest",
            base_url="http://localhost:11434"
        )
        
        # ç®€å•æµ‹è¯•
        response = llm.invoke("ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•")
        print("âœ… Ollamaè¿æ¥æˆåŠŸ")
        print(f"æµ‹è¯•å“åº”: {response}")
        return True
        
    except Exception as e:
        print(f"âŒ Ollamaè¿æ¥å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿:")
        print("1. OllamaæœåŠ¡å·²å¯åŠ¨: ollama serve")
        print("2. æ¨¡å‹å·²å®‰è£…: ollama pull gpt-3.5-turbo:latest")
        return False

if __name__ == "__main__":
    print("ğŸ” æµ‹è¯•Ollamaè¿æ¥...")
    test_ollama_connection()